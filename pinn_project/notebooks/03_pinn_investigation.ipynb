{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Activity 3: Physics-Informed ML Investigation\n",
                "\n",
                "**Duration**: 2 hours\n",
                "\n",
                "**Learning Objectives**:\n",
                "- Demonstrate how physics constraints improve machine learning predictions\n",
                "- Compare baseline vs physics-informed neural network performance\n",
                "- Conduct constraint ablation to discover which physics principles help most\n",
                "- Learn that \"adding physics\" requires validationâ€”not all constraints help!\n",
                "\n",
                "## Background\n",
                "\n",
                "A Physics-Informed Neural Network (PINN) embeds domain knowledge directly into the learning process through custom loss functions. Instead of just minimizing prediction error, the network also minimizes violation of known physics:\n",
                "\n",
                "$$\\mathcal{L}_{total} = \\mathcal{L}_{data} + \\lambda_s \\mathcal{L}_{smooth} + \\lambda_p \\mathcal{L}_{positive} + \\lambda_g \\mathcal{L}_{gradient}$$\n",
                "\n",
                "where:\n",
                "- **Smoothness**: Dose varies continuously in space\n",
                "- **Positivity**: Energy deposition cannot be negative  \n",
                "- **Gradient correlation**: dE/dx should correlate with Bethe-Bloch theory"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Setup\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import matplotlib.pyplot as plt\n",
                "from tensorflow import keras\n",
                "import sys\n",
                "sys.path.append('..')\n",
                "\n",
                "plt.style.use('seaborn-v0_8-whitegrid')\n",
                "plt.rcParams['figure.figsize'] = (10, 6)\n",
                "plt.rcParams['font.size'] = 12\n",
                "\n",
                "print(\"Setup complete!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Part 1: Load Pre-trained Models\n",
                "\n",
                "We have two pre-trained models:\n",
                "1. **Baseline NN**: Standard neural network trained only on data\n",
                "2. **Physics-Informed NN (PINN)**: Same architecture but trained with physics constraints"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load models\n",
                "baseline_model = keras.models.load_model('../models/baseline_nn.keras')\n",
                "pinn_model = keras.models.load_model('../models/advanced_pinn.keras')\n",
                "\n",
                "print(\"Baseline Model:\")\n",
                "baseline_model.summary()\n",
                "\n",
                "print(\"\\n\" + \"=\"*50)\n",
                "print(\"\\nPhysics-Informed Model:\")\n",
                "pinn_model.summary()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### ðŸ“ Question 1\n",
                "Both models have identical architectures. What makes the PINN \"physics-informed\"?\n",
                "\n",
                "*Your answer:*"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Part 2: Load Test Data\n",
                "\n",
                "We reserved energies 200 MeV and 750 MeV for testingâ€”these were NOT used during training."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load test data\n",
                "import joblib\n",
                "\n",
                "try:\n",
                "    test_df = pd.read_csv('../data/test_split_v2.csv')\n",
                "    scaler_features = joblib.load('../data/scaler_features_v2.pkl')\n",
                "    scaler_target = joblib.load('../data/scaler_target_v2.pkl')\n",
                "except FileNotFoundError:\n",
                "    test_df = pd.read_csv('../../pinn_data/test_split_v2.csv')\n",
                "    scaler_features = joblib.load('../../pinn_data/scaler_features_v2.pkl')\n",
                "    scaler_target = joblib.load('../../pinn_data/scaler_target_v2.pkl')\n",
                "\n",
                "print(f\"Test set: {len(test_df)} samples\")\n",
                "print(f\"Test energies: {test_df['energy_MeV'].unique()} MeV\")\n",
                "\n",
                "# Prepare features\n",
                "feature_cols = ['energy_MeV', 'depth_mm', 'beta', 'gamma', 'momentum_MeV_c']\n",
                "X_test = test_df[feature_cols].values\n",
                "y_test = test_df['dEdx_MeV_per_mm'].values.reshape(-1, 1)\n",
                "\n",
                "# Scale\n",
                "X_test_scaled = scaler_features.transform(X_test)\n",
                "y_test_scaled = scaler_target.transform(y_test)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Part 3: Compare Predictions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Make predictions\n",
                "baseline_pred_scaled = baseline_model.predict(X_test_scaled, verbose=0)\n",
                "pinn_pred_scaled = pinn_model.predict(X_test_scaled, verbose=0)\n",
                "\n",
                "# Inverse transform\n",
                "baseline_pred = scaler_target.inverse_transform(baseline_pred_scaled)\n",
                "pinn_pred = scaler_target.inverse_transform(pinn_pred_scaled)\n",
                "\n",
                "# Calculate errors\n",
                "baseline_mse = np.mean((baseline_pred - y_test)**2)\n",
                "pinn_mse = np.mean((pinn_pred - y_test)**2)\n",
                "\n",
                "baseline_mape = np.mean(np.abs((baseline_pred - y_test) / y_test)) * 100\n",
                "pinn_mape = np.mean(np.abs((pinn_pred - y_test) / y_test)) * 100\n",
                "\n",
                "improvement = (baseline_mse - pinn_mse) / baseline_mse * 100\n",
                "\n",
                "print(\"=== MODEL COMPARISON ON TEST SET ===\")\n",
                "print(f\"\\nBaseline NN:\")\n",
                "print(f\"  MSE:  {baseline_mse:.6f}\")\n",
                "print(f\"  MAPE: {baseline_mape:.2f}%\")\n",
                "\n",
                "print(f\"\\nPhysics-Informed NN:\")\n",
                "print(f\"  MSE:  {pinn_mse:.6f}\")\n",
                "print(f\"  MAPE: {pinn_mape:.2f}%\")\n",
                "\n",
                "print(f\"\\nðŸŽ¯ PINN Improvement: {improvement:.1f}%\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### ðŸ“ Question 2\n",
                "The PINN achieves substantially lower error on unseen test energies. Why would physics constraints help with *generalization* to new conditions?\n",
                "\n",
                "*Your answer:*"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize predictions\n",
                "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
                "\n",
                "for idx, energy in enumerate([200, 750]):\n",
                "    ax = axes[idx]\n",
                "    mask = test_df['energy_MeV'] == energy\n",
                "    \n",
                "    depths = test_df.loc[mask, 'depth_mm'].values\n",
                "    truth = y_test[mask]\n",
                "    baseline = baseline_pred[mask]\n",
                "    pinn = pinn_pred[mask]\n",
                "    \n",
                "    ax.plot(depths, truth, 'ko-', label='TOPAS (truth)', markersize=8, linewidth=2)\n",
                "    ax.plot(depths, baseline, 'b^--', label='Baseline NN', markersize=8, linewidth=2, alpha=0.7)\n",
                "    ax.plot(depths, pinn, 'rs-', label='Physics-Informed NN', markersize=8, linewidth=2, alpha=0.7)\n",
                "    \n",
                "    ax.set_xlabel('Depth (mm)', fontsize=14)\n",
                "    ax.set_ylabel('dE/dx (MeV/mm)', fontsize=14)\n",
                "    ax.set_title(f'Test Energy: {energy} MeV', fontsize=14)\n",
                "    ax.legend(fontsize=11)\n",
                "    ax.grid(True, alpha=0.3)\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Part 4: Ablation Study\n",
                "\n",
                "Now we investigate *which* physics constraints actually help. Students often assume \"more physics is better\"â€”but is that true?\n",
                "\n",
                "Let's load pre-computed ablation results where each constraint was tested individually and in combination."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Load ablation results\n",
                "ablation_df = pd.read_csv('../results/ablation_study.csv')\n",
                "print(\"Ablation Study Results:\")\n",
                "print(ablation_df.to_string(index=False))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Visualize ablation\n",
                "fig, ax = plt.subplots(figsize=(12, 6))\n",
                "\n",
                "configs = ablation_df['configuration'].values\n",
                "improvements = ablation_df['improvement_percent'].values\n",
                "\n",
                "colors = ['green' if x > 0 else 'red' for x in improvements]\n",
                "bars = ax.barh(configs, improvements, color=colors, alpha=0.7, edgecolor='black')\n",
                "\n",
                "ax.axvline(x=0, color='black', linewidth=2)\n",
                "ax.set_xlabel('Improvement vs Baseline (%)', fontsize=14)\n",
                "ax.set_title('Physics Constraint Ablation Study', fontsize=16)\n",
                "\n",
                "# Add value labels\n",
                "for bar, val in zip(bars, improvements):\n",
                "    ax.text(val + 2 if val > 0 else val - 8, bar.get_y() + bar.get_height()/2, \n",
                "            f'{val:+.1f}%', va='center', fontsize=11, fontweight='bold')\n",
                "\n",
                "plt.tight_layout()\n",
                "plt.show()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### ðŸ“ Question 3 (Critical!)\n",
                "\n",
                "Look carefully at the ablation results:\n",
                "\n",
                "1. Which constraint provides the *largest* improvement?\n",
                "2. Which constraint actually *hurts* performance when used alone?\n",
                "3. Why might the gradient constraint (based on Bethe-Bloch theory) degrade performance?\n",
                "\n",
                "*Your answers:*"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Part 5: The Surprising Lesson\n",
                "\n",
                "### The gradient constraint HURTS performance!\n",
                "\n",
                "This is a profound teaching moment. The gradient constraint is based on the **Bethe-Bloch formula**â€”one of the most respected equations in radiation physics. Yet forcing the neural network to match it makes predictions *worse*.\n",
                "\n",
                "**Why?**\n",
                "\n",
                "The Bethe-Bloch formula is an **approximation** that:\n",
                "- Assumes only electromagnetic interactions\n",
                "- Ignores nuclear reactions\n",
                "- Ignores energy straggling\n",
                "- Ignores density effects at high energy\n",
                "\n",
                "Our TOPAS simulations include ALL of this physics. Forcing the network to match the simpler Bethe-Bloch theory conflicts with the more complete simulation data!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Illustrate the conflict\n",
                "print(\"=\" * 60)\n",
                "print(\"KEY LESSON: Physics constraints must themselves be validated!\")\n",
                "print(\"=\" * 60)\n",
                "print()\n",
                "print(\"What the gradient constraint enforces:\")\n",
                "print(\"  dE/dx âˆ Î²^{-2} (Bethe-Bloch approximation)\")\n",
                "print()\n",
                "print(\"What TOPAS simulates:\")\n",
                "print(\"  dE/dx = electronic + nuclear + straggling + ...\")\n",
                "print()\n",
                "print(\"The conflict:\")\n",
                "print(\"  Forcing the network to match Bethe-Bloch conflicts with\")\n",
                "print(\"  the more complete physics in the simulation data.\")\n",
                "print()\n",
                "print(\"The lesson:\")\n",
                "print(\"  'Adding physics' is NOT automatically good.\")\n",
                "print(\"  Physics constraints must be validated empirically!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### ðŸ“ Question 4\n",
                "This finding has implications beyond radiation transport. In what other contexts might \"adding physics\" to an ML model be counterproductive?\n",
                "\n",
                "*Your answer:*"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Part 6: Your Own Investigation\n",
                "\n",
                "**Challenge**: Propose a new physics constraint that might help the model.\n",
                "\n",
                "Examples to consider:\n",
                "- Conservation constraints (energy, momentum)\n",
                "- Boundary conditions (e.g., dose at infinite depth â†’ 0)\n",
                "- Symmetry constraints\n",
                "\n",
                "For each proposed constraint:\n",
                "1. What physical principle does it encode?\n",
                "2. How would you implement it mathematically?\n",
                "3. What could go wrong? (Think about the gradient constraint lesson!)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "*Your proposed constraint and analysis:*\n",
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "---\n",
                "\n",
                "## Summary\n",
                "\n",
                "In this activity, you learned:\n",
                "\n",
                "1. **Physics constraints substantially improve ML generalization** by restricting the model to physically plausible solutions\n",
                "\n",
                "2. **Not all physics constraints help!** The gradient constraint (based on Bethe-Bloch) actually degraded performance because it conflicts with the more complete physics in the simulation.\n",
                "\n",
                "3. **\"Adding physics\" requires validation**â€”even well-established physics formulas have domains of validity.\n",
                "\n",
                "4. **The ablation study teaches the validation mindset**: test your assumptions empirically, don't just trust intuition.\n",
                "\n",
                "### Key Teaching Points\n",
                "\n",
                "> \"Machine learning works best when combined with domain knowledge, not when used as a pure black-box interpolator.\"\n",
                "\n",
                "> \"Physics constraints must themselves be validatedâ€”'adding physics' is not automatic.\"\n",
                "\n",
                "> \"The bias-variance tradeoff: adding constraints (bias) reduces overfitting (variance) when constraints align with reality.\""
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python",
            "version": "3.10.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}